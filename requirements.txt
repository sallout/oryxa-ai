fastapi>=0.100.0,<1.0.0
uvicorn[standard]>=0.20.0,<1.0.0
pydantic>=2.0,<3.0
transformers>=4.38.0,<5.0
torch>=2.0.0
llama-cpp-python>=0.2.60